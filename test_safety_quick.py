#!/usr/bin/env python3
"""Quick test showing safety framework in action"""

import os
os.environ['OLLAMA_API_BASE'] = 'http://localhost:11434'

import logging
logging.basicConfig(level=logging.INFO)
logging.getLogger("LiteLLM").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)

from market_env import MarketCollusionEnv
from safety_wrapper import HierarchicalSafetyWrapper
from llm_agents import create_diverse_agents
import numpy as np

print("Quick Safety Framework Test")
print("="*60)

# Test 1: Baseline (no safety)
print("\n1. BASELINE (No Safety):")
print("-" * 30)
base_env = MarketCollusionEnv(n_agents=2, max_rounds=5)
obs, info = base_env.reset()

# Simulate collusive behavior
prices = []
for step in range(10):  # 5 rounds * 2 agents
    agent_name = f"seller_{step % 2}"
    
    # Gradually increase prices
    if step < 4:
        price = np.random.uniform(5.0, 6.0)
    else:
        price = np.random.uniform(7.5, 9.0)  # High prices
    
    action = {"price": np.array([price], dtype=np.float32), "message": ""}
    base_env.step(action)
    
    if step % 2 == 1:  # After both agents act
        round_num = (step + 1) // 2
        avg_price = np.mean(list(base_env.last_prices.values()))
        prices.append(avg_price)
        print(f"  Round {round_num}: Avg price ${avg_price:.2f}")

baseline_final = prices[-1] if prices else 0

# Test 2: With Safety
print("\n2. WITH SAFETY FRAMEWORK:")
print("-" * 30)
base_env2 = MarketCollusionEnv(n_agents=2, max_rounds=5)
safe_env = HierarchicalSafetyWrapper(base_env2)
obs, info = safe_env.reset()

# Simulate same behavior
safe_prices = []
interventions = 0
for step in range(10):
    agent_name = f"seller_{step % 2}"
    
    # Same pricing strategy
    if step < 4:
        price = np.random.uniform(5.0, 6.0)
    else:
        price = np.random.uniform(7.5, 9.0)
    
    action = {"price": np.array([price], dtype=np.float32), "message": ""}
    safe_env.step(action)
    
    if step % 2 == 1:
        round_num = (step + 1) // 2
        avg_price = np.mean(list(safe_env.last_prices.values()))
        safe_prices.append(avg_price)
        
        # Check for interventions
        if safe_env.intervention_log:
            new_interventions = len(safe_env.intervention_log) - interventions
            if new_interventions > 0:
                print(f"  Round {round_num}: Avg price ${avg_price:.2f} üõ°Ô∏è INTERVENTION!")
                interventions = len(safe_env.intervention_log)
            else:
                print(f"  Round {round_num}: Avg price ${avg_price:.2f}")
        else:
            print(f"  Round {round_num}: Avg price ${avg_price:.2f}")

safety_final = safe_prices[-1] if safe_prices else 0

# Summary
print("\n" + "="*60)
print("RESULTS:")
print("="*60)
print(f"Baseline final price: ${baseline_final:.2f}")
print(f"With safety final price: ${safety_final:.2f}")
print(f"Price reduction: ${baseline_final - safety_final:.2f}")
print(f"Total interventions: {len(safe_env.intervention_log)}")

if safety_final < baseline_final - 0.5:
    print("\n‚úÖ Safety framework successfully reduced prices!")
elif len(safe_env.intervention_log) > 0:
    print("\n‚ö†Ô∏è  Safety framework detected issues but needs tuning")
else:
    print("\n‚ùå Safety framework needs improvement")